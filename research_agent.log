2025-01-26 12:53:18,302 - __main__ - INFO - API Key configurada correctamente
2025-01-26 12:53:18,542 - __main__ - INFO - Sesión de chat inicializada
2025-01-26 12:57:26,260 - __main__ - INFO - API Key configurada correctamente
2025-01-26 12:58:21,850 - __main__ - INFO - API Key configurada correctamente
2025-01-26 12:58:42,861 - __main__ - INFO - Nueva consulta: Can you find 8 papers on quantum machine learning?...
2025-01-26 12:58:43,573 - __main__ - INFO - Proceso completado
2025-01-26 12:58:43,581 - __main__ - ERROR - Error crítico: must be called with a dataclass type or instance
Traceback (most recent call last):
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 40, in handle_async_errors
    yield
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 168, in main
    response = asyncio.run(
               ^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py", line 684, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\astream_events_handler.py", line 29, in execute_research_flow
    async for event in workflow.astream_events({"messages": messages}, config = config, version="v2"):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1386, in astream_events
    async for event in event_stream:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 1012, in _astream_events_implementation_v2
    await task
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 967, in consume_astream
    async for _ in event_streamer.tap_output_aiter(run_id, stream):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\__init__.py", line 1899, in astream
    async for _ in runner.atick(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\runner.py", line 370, in atick
    await arun_with_retry(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\retry.py", line 123, in arun_with_retry
    async for _ in task.proc.astream(task.input, config):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 608, in astream
    async for chunk in aiterator:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1016, in astream
    yield await self.ainvoke(input, config, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 275, in ainvoke
    ret = await asyncio.create_task(coro, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 588, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 579, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\nodes\decision_making_node.py", line 16, in run
    runtime_config = AgentConfiguration.from_runnable_config(config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\configuration.py", line 39, in from_runnable_config
    for f in fields(cls)
             ^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\dataclasses.py", line 1280, in fields
    raise TypeError('must be called with a dataclass type or instance') from None
TypeError: must be called with a dataclass type or instance
During task with name 'decision_making' and id 'dbb9d4a0-aae2-79c0-dd88-785285cb9c2b'
2025-01-26 13:01:05,260 - __main__ - INFO - Nueva consulta: 
Can you find 8 papers on quantum machine learning?...
2025-01-26 13:01:05,419 - __main__ - INFO - Proceso completado
2025-01-26 13:01:05,420 - __main__ - ERROR - Error crítico: 1 validation error for AgentConfiguration
max_research_cycles
  Field required [type=missing, input_value={'llm_model': 'gpt-4o-min...eea9199a96c_5cec87deda'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.9/v/missing
Traceback (most recent call last):
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 40, in handle_async_errors
    yield
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 168, in main
    response = asyncio.run(
               ^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py", line 684, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\astream_events_handler.py", line 29, in execute_research_flow
    async for event in workflow.astream_events({"messages": messages}, config = config, version="v2"):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1386, in astream_events
    async for event in event_stream:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 1012, in _astream_events_implementation_v2
    await task
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 967, in consume_astream
    async for _ in event_streamer.tap_output_aiter(run_id, stream):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\__init__.py", line 1899, in astream
    async for _ in runner.atick(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\runner.py", line 370, in atick
    await arun_with_retry(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\retry.py", line 123, in arun_with_retry
    async for _ in task.proc.astream(task.input, config):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 608, in astream
    async for chunk in aiterator:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1016, in astream
    yield await self.ainvoke(input, config, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 275, in ainvoke
    ret = await asyncio.create_task(coro, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 588, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 579, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\nodes\decision_making_node.py", line 16, in run
    runtime_config = AgentConfiguration.from_runnable_config(config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\configuration.py", line 51, in from_runnable_config
    return cls(**values)
           ^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\pydantic\main.py", line 212, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for AgentConfiguration
max_research_cycles
  Field required [type=missing, input_value={'llm_model': 'gpt-4o-min...eea9199a96c_5cec87deda'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.9/v/missing
During task with name 'decision_making' and id '989734ef-2425-8a04-e30b-cd5573162a73'
2025-01-26 13:10:00,514 - __main__ - INFO - API Key configurada correctamente
2025-01-26 13:10:00,765 - __main__ - INFO - Sesión de chat inicializada
2025-01-26 13:10:11,454 - __main__ - INFO - Nueva consulta: Can you find 8 papers on quantum machine learning?...
2025-01-26 13:10:11,701 - __main__ - INFO - Proceso completado
2025-01-26 13:10:11,706 - __main__ - ERROR - Error crítico: 1 validation error for AgentConfiguration
max_research_cycles
  Field required [type=missing, input_value={'llm_model': 'gpt-4o-min...eea9199a96c_5cec87deda'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.9/v/missing
Traceback (most recent call last):
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 40, in handle_async_errors
    yield
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 178, in main
    response = asyncio.run(
               ^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py", line 684, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\astream_events_handler.py", line 29, in execute_research_flow
    async for event in workflow.astream_events({"messages": messages}, config = config, version="v2"):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1386, in astream_events
    async for event in event_stream:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 1012, in _astream_events_implementation_v2
    await task
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 967, in consume_astream
    async for _ in event_streamer.tap_output_aiter(run_id, stream):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\__init__.py", line 1899, in astream
    async for _ in runner.atick(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\runner.py", line 370, in atick
    await arun_with_retry(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\retry.py", line 123, in arun_with_retry
    async for _ in task.proc.astream(task.input, config):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 608, in astream
    async for chunk in aiterator:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1016, in astream
    yield await self.ainvoke(input, config, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 275, in ainvoke
    ret = await asyncio.create_task(coro, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 588, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 579, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\nodes\decision_making_node.py", line 16, in run
    runtime_config = AgentConfiguration.from_runnable_config(config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\configuration.py", line 51, in from_runnable_config
    return cls(**values)
           ^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\pydantic\main.py", line 212, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
pydantic_core._pydantic_core.ValidationError: 1 validation error for AgentConfiguration
max_research_cycles
  Field required [type=missing, input_value={'llm_model': 'gpt-4o-min...eea9199a96c_5cec87deda'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.9/v/missing
During task with name 'decision_making' and id 'd1188ba0-5312-b474-e8f5-f5fd3980829b'
2025-01-26 13:11:32,524 - langsmith.client - WARNING - Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/multipart', '{"detail":"Empty request"}')
2025-01-26 13:12:58,693 - __main__ - INFO - Nueva consulta: Can you find 8 papers on quantum machine learning?...
2025-01-26 13:13:00,948 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:13:00,957 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:13:01,052 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-01-26 13:13:01,321 - __main__ - INFO - Proceso completado
2025-01-26 13:13:01,322 - __main__ - ERROR - Error crítico: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************howA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
Traceback (most recent call last):
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 40, in handle_async_errors
    yield
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 178, in main
    response = asyncio.run(
               ^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py", line 684, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\astream_events_handler.py", line 30, in execute_research_flow
    async for event in workflow.astream_events({"messages": messages}, config = config, version="v2"):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1386, in astream_events
    async for event in event_stream:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 1012, in _astream_events_implementation_v2
    await task
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 967, in consume_astream
    async for _ in event_streamer.tap_output_aiter(run_id, stream):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\__init__.py", line 1899, in astream
    async for _ in runner.atick(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\runner.py", line 370, in atick
    await arun_with_retry(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\retry.py", line 123, in arun_with_retry
    async for _ in task.proc.astream(task.input, config):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 608, in astream
    async for chunk in aiterator:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1016, in astream
    yield await self.ainvoke(input, config, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 275, in ainvoke
    ret = await asyncio.create_task(coro, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 588, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 579, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\nodes\decision_making_node.py", line 26, in run
    response = model.invoke([system_prompt] + state["messages"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 3020, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 5352, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 790, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 647, in generate
    raise e
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 637, in generate
    self._generate_with_cache(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 843, in _generate_with_cache
    for chunk in self._stream(messages, stop=stop, **kwargs):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_openai\chat_models\base.py", line 725, in _stream
    with context_manager as response:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\lib\streaming\chat\_completions.py", line 148, in __enter__
    raw_stream = self.__api_request()
                 ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions.py", line 859, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************howA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
During task with name 'decision_making' and id '4e04c7b2-c8d7-f6f5-ef46-429b266d6c7e'
2025-01-26 13:13:01,704 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:13:01,708 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:21:14,123 - __main__ - INFO - Nueva consulta: Can you find 8 papers on quantum machine learning?...
2025-01-26 13:21:16,701 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-01-26 13:21:16,728 - __main__ - INFO - Proceso completado
2025-01-26 13:21:16,729 - __main__ - ERROR - Error crítico: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************howA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
Traceback (most recent call last):
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 50, in handle_async_errors
    yield
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 185, in main
    response = asyncio.run(
               ^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py", line 684, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\astream_events_handler.py", line 30, in execute_research_flow
    async for event in workflow.astream_events({"messages": messages}, config = config, version="v2"):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1386, in astream_events
    async for event in event_stream:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 1012, in _astream_events_implementation_v2
    await task
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 967, in consume_astream
    async for _ in event_streamer.tap_output_aiter(run_id, stream):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\__init__.py", line 1899, in astream
    async for _ in runner.atick(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\runner.py", line 370, in atick
    await arun_with_retry(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\retry.py", line 123, in arun_with_retry
    async for _ in task.proc.astream(task.input, config):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 608, in astream
    async for chunk in aiterator:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1016, in astream
    yield await self.ainvoke(input, config, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 275, in ainvoke
    ret = await asyncio.create_task(coro, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 588, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 579, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\nodes\decision_making_node.py", line 26, in run
    response = model.invoke([system_prompt] + state["messages"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 3020, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 5352, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 790, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 647, in generate
    raise e
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 637, in generate
    self._generate_with_cache(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 843, in _generate_with_cache
    for chunk in self._stream(messages, stop=stop, **kwargs):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_openai\chat_models\base.py", line 725, in _stream
    with context_manager as response:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\lib\streaming\chat\_completions.py", line 148, in __enter__
    raw_stream = self.__api_request()
                 ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions.py", line 859, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************howA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
During task with name 'decision_making' and id '8b4518cb-5916-760a-2764-b54c16852058'
2025-01-26 13:22:34,943 - langsmith.client - WARNING - Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/multipart', '{"detail":"Empty request"}')
2025-01-26 13:22:37,683 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:22:37,685 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:23:23,616 - __main__ - INFO - Nueva consulta: Can you find 8 papers on quantum machine learning?...
2025-01-26 13:23:26,173 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-01-26 13:23:26,209 - __main__ - INFO - Proceso completado
2025-01-26 13:23:26,210 - __main__ - ERROR - Error crítico: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************howA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
Traceback (most recent call last):
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 50, in handle_async_errors
    yield
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 185, in main
    response = asyncio.run(
               ^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py", line 684, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\astream_events_handler.py", line 30, in execute_research_flow
    async for event in workflow.astream_events({"messages": messages}, config = config, version="v2"):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1386, in astream_events
    async for event in event_stream:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 1012, in _astream_events_implementation_v2
    await task
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 967, in consume_astream
    async for _ in event_streamer.tap_output_aiter(run_id, stream):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\__init__.py", line 1899, in astream
    async for _ in runner.atick(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\runner.py", line 370, in atick
    await arun_with_retry(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\retry.py", line 123, in arun_with_retry
    async for _ in task.proc.astream(task.input, config):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 608, in astream
    async for chunk in aiterator:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1016, in astream
    yield await self.ainvoke(input, config, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 275, in ainvoke
    ret = await asyncio.create_task(coro, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 588, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 579, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\nodes\decision_making_node.py", line 26, in run
    response = model.invoke([system_prompt] + state["messages"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 3020, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 5352, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 790, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 647, in generate
    raise e
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 637, in generate
    self._generate_with_cache(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 843, in _generate_with_cache
    for chunk in self._stream(messages, stop=stop, **kwargs):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_openai\chat_models\base.py", line 725, in _stream
    with context_manager as response:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\lib\streaming\chat\_completions.py", line 148, in __enter__
    raw_stream = self.__api_request()
                 ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions.py", line 859, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************howA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
During task with name 'decision_making' and id '48e34766-fbe9-e9e6-3b02-1efcd8a7ac19'
2025-01-26 13:23:27,075 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:23:27,076 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:24:55,807 - __main__ - INFO - Nueva consulta: Can you find 8 papers on quantum machine learning?...
2025-01-26 13:25:03,742 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:25:03,873 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:25:03,953 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-01-26 13:25:04,055 - __main__ - INFO - Proceso completado
2025-01-26 13:25:04,126 - __main__ - ERROR - Error crítico: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************howA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
Traceback (most recent call last):
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 50, in handle_async_errors
    yield
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 185, in main
    response = asyncio.run(
               ^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py", line 684, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\astream_events_handler.py", line 30, in execute_research_flow
    async for event in workflow.astream_events({"messages": messages}, config = config, version="v2"):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1386, in astream_events
    async for event in event_stream:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 1012, in _astream_events_implementation_v2
    await task
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 967, in consume_astream
    async for _ in event_streamer.tap_output_aiter(run_id, stream):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\__init__.py", line 1899, in astream
    async for _ in runner.atick(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\runner.py", line 370, in atick
    await arun_with_retry(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\retry.py", line 123, in arun_with_retry
    async for _ in task.proc.astream(task.input, config):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 608, in astream
    async for chunk in aiterator:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1016, in astream
    yield await self.ainvoke(input, config, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 275, in ainvoke
    ret = await asyncio.create_task(coro, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 588, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 579, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\nodes\decision_making_node.py", line 26, in run
    response = model.invoke([system_prompt] + state["messages"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 3020, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 5352, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 790, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 647, in generate
    raise e
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 637, in generate
    self._generate_with_cache(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 843, in _generate_with_cache
    for chunk in self._stream(messages, stop=stop, **kwargs):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_openai\chat_models\base.py", line 725, in _stream
    with context_manager as response:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\lib\streaming\chat\_completions.py", line 148, in __enter__
    raw_stream = self.__api_request()
                 ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions.py", line 859, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************howA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
During task with name 'decision_making' and id '427c0d7c-569e-837b-c39d-e8472a561f7b'
2025-01-26 13:25:04,653 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:25:04,937 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:26:32,307 - __main__ - INFO - Sesión de chat inicializada
2025-01-26 13:26:47,657 - __main__ - INFO - Nueva consulta: Can you find 8 papers on quantum machine learning?...
2025-01-26 13:26:54,790 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-01-26 13:26:54,810 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:26:55,165 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:26:55,552 - __main__ - INFO - Proceso completado
2025-01-26 13:26:55,633 - __main__ - ERROR - Error crítico: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************howA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
Traceback (most recent call last):
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 50, in handle_async_errors
    yield
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 185, in main
    response = asyncio.run(
               ^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py", line 684, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\astream_events_handler.py", line 30, in execute_research_flow
    async for event in workflow.astream_events({"messages": messages}, config = config, version="v2"):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1386, in astream_events
    async for event in event_stream:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 1012, in _astream_events_implementation_v2
    await task
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 967, in consume_astream
    async for _ in event_streamer.tap_output_aiter(run_id, stream):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\__init__.py", line 1899, in astream
    async for _ in runner.atick(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\runner.py", line 370, in atick
    await arun_with_retry(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\retry.py", line 123, in arun_with_retry
    async for _ in task.proc.astream(task.input, config):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 608, in astream
    async for chunk in aiterator:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1016, in astream
    yield await self.ainvoke(input, config, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 275, in ainvoke
    ret = await asyncio.create_task(coro, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 588, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 579, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\nodes\decision_making_node.py", line 26, in run
    response = model.invoke([system_prompt] + state["messages"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 3020, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 5352, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 790, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 647, in generate
    raise e
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 637, in generate
    self._generate_with_cache(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 843, in _generate_with_cache
    for chunk in self._stream(messages, stop=stop, **kwargs):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_openai\chat_models\base.py", line 725, in _stream
    with context_manager as response:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\lib\streaming\chat\_completions.py", line 148, in __enter__
    raw_stream = self.__api_request()
                 ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions.py", line 859, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************howA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
During task with name 'decision_making' and id 'b7f2651a-6d41-1e5a-f7b6-4e90123bc4e5'
2025-01-26 13:26:55,939 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:26:56,997 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:28:03,537 - __main__ - INFO - Sesión de chat inicializada
2025-01-26 13:28:12,667 - __main__ - INFO - Nueva consulta: Can you find 8 papers on quantum machine learning?...
2025-01-26 13:28:14,902 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:28:14,904 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:28:15,211 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
2025-01-26 13:28:15,242 - __main__ - INFO - Proceso completado
2025-01-26 13:28:15,246 - __main__ - ERROR - Error crítico: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************howA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
Traceback (most recent call last):
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 50, in handle_async_errors
    yield
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 185, in main
    response = asyncio.run(
               ^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py", line 684, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\astream_events_handler.py", line 30, in execute_research_flow
    async for event in workflow.astream_events({"messages": messages}, config = config, version="v2"):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1386, in astream_events
    async for event in event_stream:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 1012, in _astream_events_implementation_v2
    await task
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 967, in consume_astream
    async for _ in event_streamer.tap_output_aiter(run_id, stream):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\__init__.py", line 1899, in astream
    async for _ in runner.atick(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\runner.py", line 370, in atick
    await arun_with_retry(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\retry.py", line 123, in arun_with_retry
    async for _ in task.proc.astream(task.input, config):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 608, in astream
    async for chunk in aiterator:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1016, in astream
    yield await self.ainvoke(input, config, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 275, in ainvoke
    ret = await asyncio.create_task(coro, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 588, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 579, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\nodes\decision_making_node.py", line 26, in run
    response = model.invoke([system_prompt] + state["messages"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 3020, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 5352, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 790, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 647, in generate
    raise e
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 637, in generate
    self._generate_with_cache(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 843, in _generate_with_cache
    for chunk in self._stream(messages, stop=stop, **kwargs):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_openai\chat_models\base.py", line 725, in _stream
    with context_manager as response:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\lib\streaming\chat\_completions.py", line 148, in __enter__
    raw_stream = self.__api_request()
                 ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions.py", line 859, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************howA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}
During task with name 'decision_making' and id 'c7a0781f-35f2-8eff-89ec-d35b73dcd8c5'
2025-01-26 13:28:16,018 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:28:16,030 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:30:17,658 - __main__ - INFO - Sesión de chat inicializada
2025-01-26 13:30:29,237 - __main__ - INFO - Nueva consulta: Can you find 8 papers on quantum machine learning?...
2025-01-26 13:30:31,914 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:30:31,915 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:30:32,729 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-01-26 13:30:32,787 - __main__ - INFO - Proceso completado
2025-01-26 13:30:32,789 - __main__ - ERROR - Error crítico: Error code: 400 - {'error': {'message': "Invalid parameter: 'response_format' of type 'json_schema' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs", 'type': 'invalid_request_error', 'param': None, 'code': None}}
Traceback (most recent call last):
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 50, in handle_async_errors
    yield
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 185, in main
    response = asyncio.run(
               ^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py", line 684, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\astream_events_handler.py", line 30, in execute_research_flow
    async for event in workflow.astream_events({"messages": messages}, config = config, version="v2"):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1386, in astream_events
    async for event in event_stream:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 1012, in _astream_events_implementation_v2
    await task
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 967, in consume_astream
    async for _ in event_streamer.tap_output_aiter(run_id, stream):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\__init__.py", line 1899, in astream
    async for _ in runner.atick(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\runner.py", line 370, in atick
    await arun_with_retry(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\retry.py", line 123, in arun_with_retry
    async for _ in task.proc.astream(task.input, config):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 608, in astream
    async for chunk in aiterator:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1016, in astream
    yield await self.ainvoke(input, config, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 275, in ainvoke
    ret = await asyncio.create_task(coro, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 588, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 579, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\nodes\decision_making_node.py", line 26, in run
    response = model.invoke([system_prompt] + state["messages"])
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 3020, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 5352, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 790, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 647, in generate
    raise e
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 637, in generate
    self._generate_with_cache(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\language_models\chat_models.py", line 843, in _generate_with_cache
    for chunk in self._stream(messages, stop=stop, **kwargs):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_openai\chat_models\base.py", line 748, in _stream
    _handle_openai_bad_request(e)
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_openai\chat_models\base.py", line 408, in _handle_openai_bad_request
    raise e
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_openai\chat_models\base.py", line 725, in _stream
    with context_manager as response:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\lib\streaming\chat\_completions.py", line 148, in __enter__
    raw_stream = self.__api_request()
                 ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 279, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions.py", line 859, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1283, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 960, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1064, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "Invalid parameter: 'response_format' of type 'json_schema' is not supported with this model. Learn more about supported models at the Structured Outputs guide: https://platform.openai.com/docs/guides/structured-outputs", 'type': 'invalid_request_error', 'param': None, 'code': None}}
During task with name 'decision_making' and id 'f60b40d9-e557-4b3f-dcc0-87b0851000d6'
2025-01-26 13:30:32,984 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:30:32,995 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:31:16,419 - __main__ - INFO - Nueva consulta: Can you find 8 papers on quantum machine learning?...
2025-01-26 13:31:19,198 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:31:19,203 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:31:20,450 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:31:21,062 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:31:21,388 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:31:24,874 - __main__ - INFO - Proceso completado
2025-01-26 13:31:24,877 - __main__ - ERROR - Error crítico: 'functools.partial' object has no attribute 'args_schema'
Traceback (most recent call last):
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 50, in handle_async_errors
    yield
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 185, in main
    response = asyncio.run(
               ^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py", line 684, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\astream_events_handler.py", line 30, in execute_research_flow
    async for event in workflow.astream_events({"messages": messages}, config = config, version="v2"):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1386, in astream_events
    async for event in event_stream:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 1012, in _astream_events_implementation_v2
    await task
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 967, in consume_astream
    async for _ in event_streamer.tap_output_aiter(run_id, stream):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 203, in tap_output_aiter
    async for chunk in output:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\__init__.py", line 1899, in astream
    async for _ in runner.atick(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\runner.py", line 370, in atick
    await arun_with_retry(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\retry.py", line 123, in arun_with_retry
    async for _ in task.proc.astream(task.input, config):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 608, in astream
    async for chunk in aiterator:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1016, in astream
    yield await self.ainvoke(input, config, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 275, in ainvoke
    ret = await asyncio.create_task(coro, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 588, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 579, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\nodes\planning_node.py", line 24, in run
    content=planning_prompt.format(tools=format_tools_description(tools))
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\prompts.py", line 97, in format_tools_description
    params = tool.args_schema.schema() if tool.args_schema else {}
                                          ^^^^^^^^^^^^^^^^
AttributeError: 'functools.partial' object has no attribute 'args_schema'
During task with name 'planning' and id 'cc5f2e30-ca03-a201-ad83-7bdd15bb841b'
2025-01-26 13:33:45,651 - __main__ - INFO - Nueva consulta: Traceback (most recent call last):
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportuni...
2025-01-26 13:33:48,105 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:33:48,106 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:33:49,289 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:33:49,680 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:33:49,744 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:33:52,807 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:33:56,924 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:33:57,139 - __main__ - INFO - Proceso completado
2025-01-26 13:33:57,140 - __main__ - ERROR - Error crítico: 'dict' object has no attribute 'max_research_cycles'
Traceback (most recent call last):
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 50, in handle_async_errors
    yield
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 185, in main
    response = asyncio.run(
               ^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py", line 684, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\astream_events_handler.py", line 30, in execute_research_flow
    async for event in workflow.astream_events({"messages": messages}, config = config, version="v2"):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1386, in astream_events
    async for event in event_stream:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 1012, in _astream_events_implementation_v2
    await task
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 967, in consume_astream
    async for _ in event_streamer.tap_output_aiter(run_id, stream):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 203, in tap_output_aiter
    async for chunk in output:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\__init__.py", line 1899, in astream
    async for _ in runner.atick(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\runner.py", line 370, in atick
    await arun_with_retry(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\retry.py", line 123, in arun_with_retry
    async for _ in task.proc.astream(task.input, config):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 608, in astream
    async for chunk in aiterator:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1471, in atransform
    async for output in self.astream(final, config, **kwargs):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1016, in astream
    yield await self.ainvoke(input, config, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 275, in ainvoke
    ret = await asyncio.create_task(coro, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\graph\graph.py", line 116, in _aroute
    result = await self.path.ainvoke(value, config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 263, in ainvoke
    ret = await asyncio.create_task(coro, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 588, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 579, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\edges\should_continue.py", line 16, in run
    return {"should_continue": self.should_continue(state, config)}
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\edges\should_continue.py", line 11, in should_continue
    max_cycles_reached = state.get("research_cycles", 0) >= config.max_research_cycles
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'dict' object has no attribute 'max_research_cycles'
During task with name 'agent' and id '60e0f888-d2a3-0604-7336-552a0d3db800'
2025-01-26 13:34:13,458 - __main__ - INFO - Nueva consulta: Can you find 8 papers on quantum machine learning?...
2025-01-26 13:34:15,895 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:34:15,897 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:34:16,606 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:34:16,873 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:34:16,874 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:34:19,307 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:34:22,607 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:34:22,874 - __main__ - INFO - Proceso completado
2025-01-26 13:34:22,874 - __main__ - ERROR - Error crítico: 'dict' object has no attribute 'max_research_cycles'
Traceback (most recent call last):
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 50, in handle_async_errors
    yield
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 185, in main
    response = asyncio.run(
               ^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py", line 684, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\astream_events_handler.py", line 30, in execute_research_flow
    async for event in workflow.astream_events({"messages": messages}, config = config, version="v2"):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1386, in astream_events
    async for event in event_stream:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 1012, in _astream_events_implementation_v2
    await task
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 967, in consume_astream
    async for _ in event_streamer.tap_output_aiter(run_id, stream):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 203, in tap_output_aiter
    async for chunk in output:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\__init__.py", line 1899, in astream
    async for _ in runner.atick(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\runner.py", line 370, in atick
    await arun_with_retry(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\retry.py", line 123, in arun_with_retry
    async for _ in task.proc.astream(task.input, config):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 608, in astream
    async for chunk in aiterator:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1471, in atransform
    async for output in self.astream(final, config, **kwargs):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1016, in astream
    yield await self.ainvoke(input, config, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 275, in ainvoke
    ret = await asyncio.create_task(coro, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\graph\graph.py", line 116, in _aroute
    result = await self.path.ainvoke(value, config)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 263, in ainvoke
    ret = await asyncio.create_task(coro, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 588, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 579, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\edges\should_continue.py", line 16, in run
    return {"should_continue": self.should_continue(state, config)}
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\edges\should_continue.py", line 11, in should_continue
    max_cycles_reached = state.get("research_cycles", 0) >= config.max_research_cycles
                                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'dict' object has no attribute 'max_research_cycles'
During task with name 'agent' and id '6fb4c11f-ac3a-11f1-2637-4fd3b11cca0b'
2025-01-26 13:35:46,198 - __main__ - INFO - Sesión de chat inicializada
2025-01-26 13:35:54,542 - __main__ - INFO - Nueva consulta: Can you find 8 papers on quantum machine learning?...
2025-01-26 13:35:57,448 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:35:57,449 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:35:58,240 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:35:58,614 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:35:58,627 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:36:00,687 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:36:03,879 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:36:04,230 - __main__ - INFO - Proceso completado
2025-01-26 13:36:04,232 - __main__ - ERROR - Error crítico: 'StructuredTool' object has no attribute 'partial'
Traceback (most recent call last):
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 50, in handle_async_errors
    yield
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 185, in main
    response = asyncio.run(
               ^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py", line 684, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\astream_events_handler.py", line 30, in execute_research_flow
    async for event in workflow.astream_events({"messages": messages}, config = config, version="v2"):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1386, in astream_events
    async for event in event_stream:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 1012, in _astream_events_implementation_v2
    await task
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 967, in consume_astream
    async for _ in event_streamer.tap_output_aiter(run_id, stream):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 203, in tap_output_aiter
    async for chunk in output:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\__init__.py", line 1899, in astream
    async for _ in runner.atick(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\runner.py", line 370, in atick
    await arun_with_retry(
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\pregel\retry.py", line 123, in arun_with_retry
    async for _ in task.proc.astream(task.input, config):
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 608, in astream
    async for chunk in aiterator:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\tracers\event_stream.py", line 180, in tap_output_aiter
    first = await py_anext(output, default=sentinel)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\utils\aiter.py", line 76, in anext_impl
    return await __anext__(iterator)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1453, in atransform
    async for ichunk in input:
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\base.py", line 1016, in astream
    yield await self.ainvoke(input, config, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langgraph\utils\runnable.py", line 275, in ainvoke
    ret = await asyncio.create_task(coro, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 588, in run_in_executor
    return await asyncio.get_running_loop().run_in_executor(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\concurrent\futures\thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\langchain_core\runnables\config.py", line 579, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\literature_research_graph\nodes\tools_node.py", line 21, in run
    tool = tools_dict[tool_call["name"]].partial(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\site-packages\pydantic\main.py", line 856, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'StructuredTool' object has no attribute 'partial'
During task with name 'tools' and id '0e053c1e-334d-6148-070f-e4c2f490856b'
2025-01-26 13:38:36,344 - __main__ - INFO - Nueva consulta: 
Can you find 8 papers on quantum machine learning?...
2025-01-26 13:38:38,344 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:38:38,345 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:38:39,191 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:38:39,574 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:38:39,574 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:38:41,807 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:38:45,107 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:38:46,963 - urllib3.poolmanager - INFO - Redirecting https://api.core.ac.uk/v3/search/outputs?q=quantum+machine+learning&limit=8 -> https://api.core.ac.uk/v3/search/outputs/?q=quantum+machine+learning&limit=8
2025-01-26 13:38:49,391 - __main__ - INFO - Proceso completado
2025-01-26 13:38:49,391 - __main__ - ERROR - Error crítico: 'str' object has no attribute 'content'
Traceback (most recent call last):
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 50, in handle_async_errors
    yield
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\app_literature_research.py", line 185, in main
    response = asyncio.run(
               ^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\AppData\Local\Programs\Python\Python312\Lib\asyncio\base_events.py", line 684, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\Ivan\Documents\IR Consulting\discovery_opportunity_agent\src\astream_events_handler.py", line 56, in execute_research_flow
    output_placeholder.code(event['data'].get('output').content)  # Muestra el output
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'content'
2025-01-26 13:42:54,214 - __main__ - INFO - Nueva consulta: 
Can you find 8 papers on quantum machine learning?...
2025-01-26 13:42:56,589 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:42:56,591 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:42:57,491 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:42:57,823 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:42:57,824 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:43:00,223 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:43:03,074 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:43:04,674 - urllib3.poolmanager - INFO - Redirecting https://api.core.ac.uk/v3/search/outputs?q=quantum+machine+learning&limit=8 -> https://api.core.ac.uk/v3/search/outputs/?q=quantum+machine+learning&limit=8
2025-01-26 13:43:09,338 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:43:24,132 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:43:24,133 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:43:24,756 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 13:43:25,111 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 13:43:25,123 - __main__ - INFO - Respuesta generada exitosamente
2025-01-26 13:43:25,133 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 13:43:25,147 - __main__ - INFO - Proceso completado
2025-01-26 19:15:06,159 - __main__ - INFO - Sesión de chat inicializada
2025-01-26 19:15:51,359 - __main__ - INFO - Nueva consulta: 
    """Find and analyze papers from 2023-2024 about the application of transformer architectures in...
2025-01-26 19:15:54,151 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:15:54,176 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:15:55,138 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:15:55,493 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:15:55,494 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:15:57,685 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:16:06,218 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:16:08,189 - urllib3.poolmanager - INFO - Redirecting https://api.core.ac.uk/v3/search/outputs?q=transformer+architectures+in+protein+folding+prediction&limit=10 -> https://api.core.ac.uk/v3/search/outputs/?q=transformer+architectures+in+protein+folding+prediction&limit=10
2025-01-26 19:16:15,604 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:16:29,994 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:16:29,994 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:16:30,688 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:16:31,709 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:16:31,711 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:16:34,295 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:16:52,895 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:16:57,085 - urllib3.poolmanager - INFO - Redirecting https://mospace.umsystem.edu/xmlui/bitstream/10355/94100/1/WuTianqiResearch.pdf -> https://mospace.umsystem.edu/xmlui/bitstream/handle/10355/94100/WuTianqiResearch.pdf;jsessionid=DFA5D3E74644B9F2228E24EAFAA58115?sequence=1
2025-01-26 19:17:12,153 - urllib3.poolmanager - INFO - Redirecting https://mospace.umsystem.edu/xmlui/bitstream/10355/94100/1/WuTianqiResearch.pdf -> https://mospace.umsystem.edu/xmlui/bitstream/handle/10355/94100/WuTianqiResearch.pdf;jsessionid=79733BDF40D10372072F583D29C3959B?sequence=1
2025-01-26 19:17:29,829 - urllib3.poolmanager - INFO - Redirecting https://mospace.umsystem.edu/xmlui/bitstream/10355/94100/1/WuTianqiResearch.pdf -> https://mospace.umsystem.edu/xmlui/bitstream/handle/10355/94100/WuTianqiResearch.pdf;jsessionid=3D8AD69E61B2B78AD6CFC2BA98C6D851?sequence=1
2025-01-26 19:17:52,715 - urllib3.poolmanager - INFO - Redirecting https://digibug.ugr.es/bitstream/10481/80621/1/2022.02.07.479394v1.full.pdf -> https://digibug.ugr.es/bitstream/handle/10481/80621/2022.02.07.479394v1.full.pdf;jsessionid=C39C06D4BFCCCD77E21E65D242E26C1A?sequence=1
2025-01-26 19:18:20,653 - __main__ - INFO - Sesión de chat inicializada
2025-01-26 19:18:32,398 - __main__ - INFO - Nueva consulta: Find and analyze papers from 2023-2024 about the application of transformer architectures in protein...
2025-01-26 19:18:34,284 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:18:34,285 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:18:34,972 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:18:35,270 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:18:35,271 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:18:37,732 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:18:45,209 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:18:47,243 - urllib3.poolmanager - INFO - Redirecting https://api.core.ac.uk/v3/search/outputs?q=transformer+architectures+protein+folding+prediction+novel+modifications+experimental+validation&limit=5 -> https://api.core.ac.uk/v3/search/outputs/?q=transformer+architectures+protein+folding+prediction+novel+modifications+experimental+validation&limit=5
2025-01-26 19:18:52,610 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:19:08,160 - urllib3.poolmanager - INFO - Redirecting https://discovery.ucl.ac.uk/10185608/1/Moffat%2C%20Lewis_LMoffat_Thesis_Corrected_Final.pdf -> https://discovery.ucl.ac.uk/id/eprint/10185608/1/Moffat, Lewis_LMoffat_Thesis_Corrected_Final.pdf
2025-01-26 19:19:19,379 - urllib3.poolmanager - INFO - Redirecting https://discovery.ucl.ac.uk/10185608/1/Moffat%2C%20Lewis_LMoffat_Thesis_Corrected_Final.pdf -> https://discovery.ucl.ac.uk/id/eprint/10185608/1/Moffat, Lewis_LMoffat_Thesis_Corrected_Final.pdf
2025-01-26 19:19:34,760 - urllib3.poolmanager - INFO - Redirecting https://discovery.ucl.ac.uk/10185608/1/Moffat%2C%20Lewis_LMoffat_Thesis_Corrected_Final.pdf -> https://discovery.ucl.ac.uk/id/eprint/10185608/1/Moffat, Lewis_LMoffat_Thesis_Corrected_Final.pdf
2025-01-26 19:19:52,904 - urllib3.poolmanager - INFO - Redirecting https://discovery.ucl.ac.uk/10185608/1/Moffat%2C%20Lewis_LMoffat_Thesis_Corrected_Final.pdf -> https://discovery.ucl.ac.uk/id/eprint/10185608/1/Moffat, Lewis_LMoffat_Thesis_Corrected_Final.pdf
2025-01-26 19:20:17,373 - urllib3.poolmanager - INFO - Redirecting https://discovery.ucl.ac.uk/10185608/1/Moffat%2C%20Lewis_LMoffat_Thesis_Corrected_Final.pdf -> https://discovery.ucl.ac.uk/id/eprint/10185608/1/Moffat, Lewis_LMoffat_Thesis_Corrected_Final.pdf
2025-01-26 19:20:58,374 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:21:02,155 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:21:02,156 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:21:03,277 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:21:04,502 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:21:04,502 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:21:06,749 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:21:16,350 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:21:18,046 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:21:18,050 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:21:18,821 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:21:20,011 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:21:20,012 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:21:22,690 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:21:36,064 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:21:39,321 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:21:39,322 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:21:39,926 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:21:41,728 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:21:41,729 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:21:44,101 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:21:56,152 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:21:58,359 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:21:58,360 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:21:59,218 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:22:01,027 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:22:01,028 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:22:03,137 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:22:14,505 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:22:16,976 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:22:16,977 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:22:17,660 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:22:19,677 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:22:19,678 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:22:22,507 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:22:35,189 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:22:37,686 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:22:37,687 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:22:38,279 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:22:40,496 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:22:40,497 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:43:07,575 - __main__ - INFO - Sesión de chat inicializada
2025-01-26 19:43:22,175 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:43:25,457 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:43:37,366 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:43:40,157 - urllib3.poolmanager - INFO - Redirecting https://api.core.ac.uk/v3/search/outputs?q=transformer+architectures+in+protein+folding+prediction+novel+architectural+modifications+experimental+validation&limit=10 -> https://api.core.ac.uk/v3/search/outputs/?q=transformer+architectures+in+protein+folding+prediction+novel+architectural+modifications+experimental+validation&limit=10
2025-01-26 19:43:49,904 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:44:11,159 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:44:15,410 - urllib3.poolmanager - INFO - Redirecting https://arxiv.org/pdf/2401.14819.pdf -> https://arxiv.org/pdf/2401.14819
2025-01-26 19:44:25,638 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:44:39,351 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:44:39,821 - __main__ - INFO - Respuesta generada exitosamente
2025-01-26 19:44:39,822 - __main__ - INFO - Proceso completado
2025-01-26 19:44:40,781 - langsmith.client - WARNING - Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('400 Client Error: Bad Request for url: https://api.smith.langchain.com/runs/multipart', '{"detail":"Empty request"}')
2025-01-26 19:44:42,269 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:44:42,271 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:44:42,308 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:44:42,317 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:46:08,641 - __main__ - INFO - Nueva consulta: Escribe un reporte de invezstigación con estos resultados...
2025-01-26 19:46:10,751 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:46:10,751 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
2025-01-26 19:46:12,973 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-01-26 19:46:38,938 - __main__ - INFO - Respuesta generada exitosamente
2025-01-26 19:46:38,939 - __main__ - INFO - Proceso completado
2025-01-26 19:46:39,191 - langsmith.client - ERROR - Failed to use model_dump to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.model_dump() missing 1 required positional argument: 'self'")
2025-01-26 19:46:39,205 - langsmith.client - ERROR - Failed to use dict to serialize <class 'pydantic._internal._model_construction.ModelMetaclass'> to JSON: TypeError("BaseModel.dict() missing 1 required positional argument: 'self'")
