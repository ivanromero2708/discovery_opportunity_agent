import os
import asyncio
import logging
import streamlit as st
from langchain_core.messages import AIMessage, HumanMessage
from dotenv import load_dotenv
from contextlib import contextmanager
from datetime import datetime
import re
import uuid  # Para generar un thread_id Ãºnico

# Importar el manejador de eventos
from astream_events_handler import execute_research_flow

# ConfiguraciÃ³n inicial de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("research_agent.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

load_dotenv()

# ConfiguraciÃ³n inicial de la pÃ¡gina
st.set_page_config(
    page_title="Investigador CientÃ­fico IA",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

@contextmanager
def handle_async_errors():
    """Maneja errores asÃ­ncronos y muestra mensajes en la UI."""
    try:
        yield
    except Exception as e:
        logger.exception(f"Error crÃ­tico: {str(e)}")
        st.error(f"ğŸš¨ Error crÃ­tico: {str(e)}")
        st.session_state.processing = False
        st.rerun()

def setup_api_key():
    """ConfiguraciÃ³n segura de API Keys con validaciÃ³n."""
    st.sidebar.header("ğŸ”‘ ConfiguraciÃ³n de API Keys")
    
    openai_key = st.sidebar.text_input(
        "OpenAI API Key",
        type="password",
        value=os.getenv("OPENAI_API_KEY", ""),
        help="ObtÃ©n tu clave en https://platform.openai.com/account/api-keys"
    )
    
    if st.sidebar.button("ğŸ’¾ Guardar Clave", type="primary"):
        if not openai_key:
            st.error("OpenAI API Key es requerida")
        else:
            os.environ["OPENAI_API_KEY"] = openai_key
            st.session_state.api_keys_set = True
            logger.info("API Key configurada correctamente")
            st.success("âœ… Clave configurada correctamente")
            st.rerun()

def initialize_chat():
    """Inicializa el estado del chat con valores por defecto."""
    if "messages" not in st.session_state:
        st.session_state.messages = [
            AIMessage(content="Â¡Hola! Soy tu asistente de investigaciÃ³n. Â¿En quÃ© tema deseas profundizar hoy?")
        ]
        st.session_state.processing = False
        logger.info("SesiÃ³n de chat inicializada")

import streamlit as st
import uuid

def display_sidebar():
    """Muestra la barra lateral con campos de configuraciÃ³n."""
    with st.sidebar:
        st.header("ğŸ”§ ConfiguraciÃ³n del AnÃ¡lisis")
        
        # Campo para seleccionar el modelo LLM
        st.session_state.research_state['llm_model'] = st.text_input(
            "Modelo LLM",
            value="gpt-4o-mini",
            help="Ejemplos: gpt-4, gpt-4o, gpt-3.5-turbo"
        )
        
        # Campo para configurar la temperatura del modelo
        st.session_state.research_state['temperature'] = st.number_input(
            "Temperatura del Modelo",
            min_value=0.0,
            max_value=2.0,
            value=0,
            step=0.1,
            help="Controla la creatividad del modelo (0.0 = determinÃ­stico, 2.0 = muy creativo)"
        )
        
        st.markdown("---")

        # BotÃ³n que genera un nuevo thread y ejecuta el anÃ¡lisis
        if st.button("ğŸ‰ Iniciar Nueva ConversaciÃ³n", use_container_width=True):
            # Creamos un nuevo thread_id con uuid
            new_thread = str(uuid.uuid4())
            st.session_state.research_state['thread_id'] = new_thread
            st.success(f"Nuevo thread iniciado: {new_thread}")

def render_chat_history():
    """Renderiza el historial del chat con formato mejorado."""
    for msg in st.session_state.messages:
        if isinstance(msg, AIMessage):
            with st.chat_message("assistant", avatar="ğŸ”¬"):
                st.markdown(msg.content)
        elif isinstance(msg, HumanMessage):
            with st.chat_message("user", avatar="ğŸ‘¤"):
                st.markdown(msg.content)

def main():
    st.title("ğŸ” Investigador CientÃ­fico Asistido por IA")
    
    setup_api_key()
    
    if not st.session_state.get("api_keys_set", False):
        st.info("âš ï¸ Configura tu API Key en la barra lateral")
        return

    initialize_chat()
    render_chat_history()
    thread_id = st.session_state.research_state['thread_id']
    config = {"configurable": {"thread_id": thread_id}, }
    
    
    if prompt := st.chat_input("Escribe tu pregunta de investigaciÃ³n..."):
        if st.session_state.processing:
            st.warning("Espera a que termine la operaciÃ³n actual")
            return

        st.session_state.processing = True
        st.session_state.messages.append(HumanMessage(content=prompt))
        logger.info(f"Nueva consulta: {prompt[:100]}...")
        
        with st.chat_message("user", avatar="ğŸ‘¤"):
            st.markdown(prompt)

        with st.chat_message("assistant", avatar="ğŸ”¬"):
            placeholder = st.empty()
            
            with handle_async_errors(), st.spinner("ğŸ” Analizando consulta..."):
                try:
                    response = asyncio.run(
                        execute_research_flow(
                            st.session_state.messages,
                            placeholder,
                            st.session_state.research_state['thread_id'],
                            st.session_state.research_state['llm_model'],
                            st.session_state.research_state['temperature']
                        )
                    )
                    
                    if response:
                        clean_response = re.sub(r"```markdown\n|\n```", "", response)
                        final_message = AIMessage(content=clean_response)
                        st.session_state.messages.append(final_message)
                        logger.info("Respuesta generada exitosamente")
                finally:
                    st.session_state.processing = False
                    logger.info("Proceso completado")

if __name__ == "__main__":
    main()